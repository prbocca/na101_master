{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI1lj248AE7o"
      },
      "source": [
        "#Práctico 4+5: Introducción a los espacios embebidos de vértices y a las redes neuronales para grafos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncrv78sv4GpD"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "En este práctico vamos a trabajar sobre métodos para representar un grafo en un espacio euclideano. \n",
        "\n",
        "Como hemos visto en el teórico podemos encontrar formas de representar los vértices de un grafo como vectores. Esto es útil por varios motivos. Por un lado, nos permite aplicar algoritmos tradicionales de aprendizaje automático (Machine Learning - ML) a estos vértices. Por otro, podemos medir distancia en la nueva representación e interpretar que vértices cercanos son similares.\n",
        "\n",
        "En este práctico vamos a utilizar, en adición a `IGraph`, la biblioteca llamada `StellarGraph` que tiene muchas utilidades para hacer ML en grafos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rE-mgnQlTxtz"
      },
      "outputs": [],
      "source": [
        "!pip install python-igraph > /dev/null\n",
        "!pip install cairocffi > /dev/null\n",
        "!pip install stellargraph > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QEfoJnvTk8t"
      },
      "outputs": [],
      "source": [
        "import igraph as ig\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "# Modules used for node2vec\n",
        "from stellargraph import StellarGraph\n",
        "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stellargraph import datasets\n",
        "from stellargraph.data import BiasedRandomWalk\n",
        "\n",
        "from IPython.display import display, HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSRZvf3Ka4jV"
      },
      "source": [
        "#1) Club de Karate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nyPfJI7N2zR"
      },
      "source": [
        "Vamos a descargar el dataset del club de karate con el que ya hemos trabajado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIPse8RlTs_s"
      },
      "outputs": [],
      "source": [
        "!wget -q \"https://raw.githubusercontent.com/prbocca/na101_master/master/homework_04_embeddings/karate.graphml\" -O \"karate.graphml\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjYwNzzdZF-B"
      },
      "outputs": [],
      "source": [
        "g_karate = ig.load(\"karate.graphml\")\n",
        "g_karate.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXy_a5k0OpaC"
      },
      "source": [
        "Como podemos ver, cada nodo cuenta con una facción (`Faction`) que viene dada por el dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDyTMTPHGT_h"
      },
      "outputs": [],
      "source": [
        "N = np.arange(g_karate.vcount())\n",
        "g_karate.vcount(), g_karate.ecount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgvWJWTCZJCo"
      },
      "outputs": [],
      "source": [
        "g_karate.vs[0].attributes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX9G4MvxPsXS"
      },
      "source": [
        "Vemos que hay tan solo 2 facciones: `1.0` y `2.0`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tr_Q-cHPPjSs"
      },
      "outputs": [],
      "source": [
        "set([n[\"Faction\"] for n in g_karate.vs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf8XssOOCHU7"
      },
      "source": [
        "Visualizamos el grafo según las facciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WoAyIDuxlxA"
      },
      "outputs": [],
      "source": [
        "g_karate.vs[\"label\"] = [s.replace(\"Actor \", \"\") for s in g_karate.vs[\"name\"]]\n",
        "\n",
        "visual_style = dict()\n",
        "visual_style[\"layout\"] = g_karate.layout()\n",
        "visual_style[\"vertex_shape\"] = [\"rectangle\" if name_ in [\"Mr Hi\", \"John A\"] else \"circle\" for name_ in g_karate.vs[\"name\"]]\n",
        "visual_style[\"vertex_color\"] = [\"red\" if type_ == 1 else \"blue\" for type_ in g_karate.vs[\"Faction\"]]\n",
        "visual_style[\"vertex_size\"] = g_karate.strength()\n",
        "visual_style[\"edge_width\"] = g_karate.es[\"weight\"]\n",
        "\n",
        "f1 = g_karate.vs.select(Faction=1)\n",
        "f2 = g_karate.vs.select(Faction=2)\n",
        "g_karate.es.select(_between=(f1, f1))[\"color\"] = \"pink\"\n",
        "g_karate.es.select(_between=(f2, f2))[\"color\"] = \"skyblue\"\n",
        "g_karate.es.select(_between=(f1, f2))[\"color\"] = \"yellow\"\n",
        "\n",
        "ig.plot(g_karate, **visual_style)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekUtna4EP0LI"
      },
      "source": [
        "##1.1) Laplacian Eigenmap\n",
        "\n",
        "Una de las formas más simples y eficaces de embember los vértices de un grafo en un espacio vectorial se conoce como `Laplacian Eigenmap`. \n",
        "\n",
        "Este método es un caso muy sencillo de embebido superficial que sigue el framework `encoder-decoder`. \n",
        "* Al ser superficial, el `encoder` es una función de mapeo (tabla): $ENC(u)=\\mathbf{Z}[u]$, donde $\\mathbf{Z} \\in \\mathbb{R}^{|V| \\times d}$, \n",
        "* y el `decoder` es la función de parejas de vectores de vértices definida:\n",
        "$$ DEC(\\mathbf{Z}[u], \\mathbf{Z}[v]) = || \\mathbf{Z}[u] - \\mathbf{Z}[v] ||_2^2.$$\n",
        "\n",
        "Cuando se entrena el espacio embebido para que la similaridad entre los vectores sea la matriz laplaciana, se puede demostrar (ver teórico) que este método de embebido corresponde a elegir $\\mathbf{Z} \\sim$ los $d$ vectores propios de $L$ de valor propio más pequeño, exceptuando el valor propio 0.\n",
        "\n",
        "Aplicaremos este resultado entonces.\n",
        "Primero, empezamos por construir el laplaciano del grafo:\n",
        "\n",
        "$$ L = D - A.$$\n",
        "\n",
        "Esto es bastante sencillo de hacer con `igraph`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g8hdu2IZLno"
      },
      "outputs": [],
      "source": [
        "L = np.array(g_karate.laplacian())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x832Opi8DDKz"
      },
      "outputs": [],
      "source": [
        "#podemos imprimir la matriz, o verla como una imagen\n",
        "display(L)\n",
        "\n",
        "plt.imshow(L)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0Y1SI-bRgpA"
      },
      "source": [
        "Luego, tenemos que calcular los valores y vectores propios del laplaciano. Esto también es fácil de hacer usando `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoeyd78oaDY6"
      },
      "outputs": [],
      "source": [
        "eig_val, eig_vec = np.linalg.eig(L)\n",
        "print(eig_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhnhbbKYEXLS"
      },
      "source": [
        "Vamos a necesitar los vectores propios ordenados de menos a mayor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqz9dbWUTKHG"
      },
      "outputs": [],
      "source": [
        "idx = eig_val.argsort()\n",
        "eig_val = eig_val[idx]\n",
        "eig_vec = eig_vec[:, idx]\n",
        "\n",
        "print(\"Los valores propios son:\\n\", eig_val)\n",
        "print(\"Los vectores propios estan en una matriz NxN:\\n\", eig_vec.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39eb6HWATUNH"
      },
      "source": [
        "En el espacio de vectores propios, a cada vértice le corresponde un vector de tamaño $N$ (donde $N$ son la cantidad de nodos en el grafo, en este caso 34).\n",
        "\n",
        "Luego, para embeber los vértices en un espacio de dimensión $d$ vamos a quedarnos con las $d$ coordenadas de cada nodo asociadas a los valores propios más chicos (sin contar el más chico de todos, ese lo ignoramos).\n",
        "\n",
        "Veamos como ejemplo sencillo $d=2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeS5bAQmazHr"
      },
      "outputs": [],
      "source": [
        "d = 2\n",
        "encoder_laplacian_eigenmap = eig_vec[:, 1: 1 + d] # El eje 0 es la cantidad de nodos y el eje 1 es la dimensión\n",
        "\n",
        "node_targets_laplacian_eigenmap = pd.Categorical(g_karate.vs[\"Faction\"]).astype(\"category\")\n",
        "\n",
        "print(\"El embebido superficial tiene dimensiones \", encoder_laplacian_eigenmap.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMt_VufsNeWV"
      },
      "source": [
        "El espacio embebido $\\mathbf{Z} \\in \\mathbb{R}^{34 \\times 2}$ de dimensión $d=2$ para los 34 vértices (ordenados según el laplaciano) es:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_UF2KvcNanY"
      },
      "outputs": [],
      "source": [
        "encoder_laplacian_eigenmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPvEcbR7WJdr"
      },
      "source": [
        "Una vez que tenemos la representación de cada nodo, podemos graficarlos. Esto es sencillo si usamos dimensión 2 (si hubiesemos elegido $d=5$ sería más difícil).\n",
        "\n",
        "Como podemos ver, esta representación hace bastante fácil separar linealmente los nodos de ambas facciones (lo cuál es una muy buena noticia par un algoritmo de inteligencia aritificial!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybProViFGKZg"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "for n in N:\n",
        "  faction = node_targets_laplacian_eigenmap[n] \n",
        "  color = \"red\" if faction == 1 else \"blue\"\n",
        "  x,y = encoder_laplacian_eigenmap[n, :]\n",
        "  ax.scatter(x, y, c=color, label=faction)\n",
        "\n",
        "ax.set_xlabel(\"1st non zero eignvector\")\n",
        "ax.set_ylabel(\"2nd non zero eignvector\")\n",
        "\n",
        "handles, labels = fig.gca().get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "ax.legend(by_label.values(), by_label.keys())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShRNC6meXqVD"
      },
      "source": [
        "##1.2) Node2Vec\n",
        "\n",
        "Otro algoritmo bastante popular y bastante más \"poderoso\" es `node2Vec`.\n",
        "\n",
        "La idea de este algoritmo es muy ingeniosa: dado que el algoritmo `word2vec` es muy bueno en representar palabras como vectores a partir de oraciones, porque no encontrar la forma de transformar vértices en palabras y reutilizar el mismo algoritmo? Y como hacemos para poder hacer esa transformación?\n",
        "\n",
        "Para entrenar un algoritmo de `node2vec` lo que se necesitan son oraciones hechas a partir de palabras.\n",
        "\n",
        "Para poder hacer esto mismo en el grafo, la idea es generar \"caminos\": que cada nodo sea interpretado como una palabra y que el camino entero sea una oración.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDaNNa7wabAq"
      },
      "source": [
        "Como habíamos mencionado antes, vamos a utilizar la bliblioteca `StellarGraph` y para esto necesitamos cargar el grafo desde `networkx`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTNq8KkivIgC"
      },
      "outputs": [],
      "source": [
        "g_karate.write_graphml(\"g_karate.graphml\") #guardo el grafo igraph con los atributos generados, para luego leerlo desde networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuHhD6GRvXRA"
      },
      "outputs": [],
      "source": [
        "G = nx.read_graphml(\"g_karate.graphml\")\n",
        "print(nx.info(G))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPQpq3OatvEL"
      },
      "outputs": [],
      "source": [
        "G_S = StellarGraph.from_networkx(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5RJboqwvmOZ"
      },
      "outputs": [],
      "source": [
        "print(G_S.info()[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vPO5fZIaZvu"
      },
      "source": [
        "Una de las ideas que hacen que `node2vec` funcione tan bien es la forma se generan los caminos en el grafo.\n",
        "\n",
        "La forma \"fácil\" sería generar muchas caminatas aleatorias a partir de cada nodo del grafo y usar eso. \n",
        "\n",
        "En lugar de eso, el algoritmo asigna distintos pesos a cada arista a la hora de generar una muestra aleatoria, haciendo el método más efectivo.\n",
        "\n",
        "En `StellarGraph` el método `BiasedRandomWalk` genera caminatas aleatorias de este estilo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt7GNFAxvrYM"
      },
      "outputs": [],
      "source": [
        "rw = BiasedRandomWalk(G_S)\n",
        "\n",
        "walks = rw.run(\n",
        "    nodes=list(G_S.nodes()),  # root nodes\n",
        "    length=80,  # maximum length of a random walk\n",
        "    n=10,  # number of random walks per root node\n",
        "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        ")\n",
        "print(\"Number of random walks: {}\".format(len(walks)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG8u8dR2eOR4"
      },
      "source": [
        "Así es como se ve una caminata aleatoria: una sequencia de nodos de largo 80."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9fxdDp0x9Bk"
      },
      "outputs": [],
      "source": [
        "walks[0][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYdU7a5ee_LG"
      },
      "source": [
        "Ahora que tenemos nuestras oraciones de nodos, lo único que tenemos que hacer es importar una implementación de `Word2Vec` y entrenar!\n",
        "\n",
        "Nuevamente usaremos como dimensión $d=2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgsm9hk8wrfC"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "d = 2\n",
        "\n",
        "str_walks = [[str(n) for n in walk] for walk in walks]\n",
        "model = Word2Vec(str_walks, size=d, window=5, min_count=0, sg=1, workers=2, iter=1)\n",
        "encoder_node2vec = np.vstack([model.wv[f\"n{i}\"] for i in N])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSkxFE6bQgz7"
      },
      "source": [
        "El espacio embebido $\\mathbf{Z} \\in \\mathbb{R}^{34 \\times 2}$ de dimensión $d=2$ para los 34 vértices es:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npgPIJRrQrG_"
      },
      "outputs": [],
      "source": [
        "encoder_node2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXEIcYDnf21p"
      },
      "source": [
        "Una vez más, como elegimos dimension $d=2$, podemos graficar el resultado del algoritmo en el plano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCo4wOcEy7hc"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "for n in N:\n",
        "  faction = int(g_karate.vs[n][\"Faction\"])\n",
        "  color = \"red\" if faction == 1 else \"blue\"\n",
        "  x,y = encoder_node2vec[n, :]\n",
        "  ax.scatter(x, y, c=color, label=faction)\n",
        "\n",
        "ax.set_xlabel(\"1st non zero eignvector\")\n",
        "ax.set_ylabel(\"2nd non zero eignvector\")\n",
        "\n",
        "handles, labels = fig.gca().get_legend_handles_labels()\n",
        "by_label = dict(zip(labels, handles))\n",
        "ax.legend(by_label.values(), by_label.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tJlduDIgBZi"
      },
      "source": [
        "##1.3) Entrenando un clasificador de facciones\n",
        "\n",
        "Hasta ahora hemos definido dos algoritmos para transformar nodos en vectores de dimensión 2. Es hora de ponerlos en uso.\n",
        "\n",
        "Para esto, vamos a entrenar un clasificador bastante simple que decida a que facción pertenece cada nodo.\n",
        "\n",
        "Como \"features\" vamos a usar la representación obtenida por cada uno de los algoritmos. Vamos a usar algunos de los nodos como conjunto de `train` y otros como conjunto de `test`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DS6hK7zzDBa"
      },
      "outputs": [],
      "source": [
        "df_laplacian = pd.DataFrame(encoder_laplacian_eigenmap, columns=[\"f1\", \"f2\"])\n",
        "df_node2vec = pd.DataFrame(encoder_node2vec, columns=[\"f1\", \"f2\"])\n",
        "\n",
        "NAMES = [\"Laplacian Eigenmap\", \"Node2Vec\"]\n",
        "dfs = [df_laplacian, df_node2vec]\n",
        "for df in dfs:\n",
        "  df[\"target\"] = [True if x == 1 else False for x in g_karate.vs[\"Faction\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQXN87Y6hjLs"
      },
      "outputs": [],
      "source": [
        "display(dfs[0].head())\n",
        "display(dfs[1].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aidg9MASxlw"
      },
      "source": [
        " Elegimos el conjunto de train con 17 vértices al azar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ4JQrD0qHhp"
      },
      "outputs": [],
      "source": [
        "r = np.random.RandomState(1234)\n",
        "train_index = r.choice(range(34), size=17, replace=False)\n",
        "\n",
        "display(train_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJsEIuEsiBtq"
      },
      "source": [
        "Lo que vamos a hacer aquí es para cada dataset, separar el conjunto de train y test para luego entrenar una regresión.\n",
        "\n",
        "Como sabemos, la regresión no puede aceptar grafos como entrada, pero no tiene problema en aceptar pares de nodos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2egDAzsqyGq"
      },
      "outputs": [],
      "source": [
        "models = []\n",
        "for i, df in enumerate(dfs):\n",
        "  train_df = df[df.index.isin(train_index)]\n",
        "  test_df = df[~df.index.isin(train_index)]\n",
        "  y_train = train_df.pop(\"target\")\n",
        "  y_test = test_df.pop(\"target\")\n",
        "\n",
        "  log_reg = LogisticRegression(random_state=r)\n",
        "  log_reg.fit(train_df, y_train)\n",
        "  predicted = log_reg.predict(test_df)\n",
        "\n",
        "  acc = accuracy_score(y_test, predicted)\n",
        "  models.append(log_reg)\n",
        "\n",
        "  print(f\"Model {NAMES[i]: <20} has an accuracy of {acc:0.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFWKBEI5iSq-"
      },
      "source": [
        "Podemos ir incluso un paso más allá y dibujar las regiones que encuentra el clasificador para ambos algoritmos. Aquí es más fácil de ver que `node2vec` es incluso un poco mejor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qskd04cprpme"
      },
      "outputs": [],
      "source": [
        "h = 0.02\n",
        "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
        "for i in range(2):\n",
        "  ax = axs[i]\n",
        "  df = dfs[i]\n",
        "  model = models[i]\n",
        "\n",
        "  x_min, x_max = df[\"f1\"].min(), df[\"f1\"].max()\n",
        "  y_min, y_max = df[\"f2\"].min(), df[\"f2\"].max()\n",
        "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
        "                      np.arange(y_min, y_max, h))\n",
        "\n",
        "  Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "  Z = Z.reshape(xx.shape)\n",
        "\n",
        "  ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.7)\n",
        "\n",
        "  for _, row in df.iterrows():\n",
        "    x, y = row[\"f1\"], row[\"f2\"]\n",
        "    color = \"red\" if row[\"target\"] else \"blue\"\n",
        "    ax.scatter(x, y, marker='.', c=color)\n",
        "  \n",
        "  ax.set_title(NAMES[i])\n",
        "  ax.set_xlabel(\"f1\")\n",
        "  ax.set_ylabel(\"f2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGRzqSNtbnzE"
      },
      "source": [
        "##1.4)  Entrenando una Graph Neural Network (GNN) con `StellarGraph`\n",
        "\n",
        "Esta parte del práctico está basada en el siguiente [blog post](https://stellargraph.readthedocs.io/en/stable/demos/node-classification/gcn-node-classification.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6ULS3JPTvrg"
      },
      "outputs": [],
      "source": [
        "import stellargraph as sg\n",
        "from stellargraph.mapper import FullBatchNodeGenerator\n",
        "from stellargraph.layer import GCN\n",
        "\n",
        "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
        "from sklearn import preprocessing, model_selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWaI32I8fIii"
      },
      "source": [
        "Recordamos que tenemos el grafo en formato `StellarGraph`. \n",
        "Como vamos a ver, el grafo todavía no tiene los atributos necesarios. Estos los vamos a agregar a continuación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpxBSmLXeScJ"
      },
      "outputs": [],
      "source": [
        "print(G_S.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t43ugKZddtAq"
      },
      "source": [
        "Lamentablemente el grafo no tiene los atributos en los vértices que necesitamos. Por tanto, mostramos otra forma de cargar el grafo.\n",
        "\n",
        "Para cargar el grafo en `StellarGraph` pasaremos de `igraph` a `pandas` y luego a `StellarGraph`. Para esto primero creamos una lista de aristas (no dirigidas y las guardamos en un dataframe). Y luego creamos un dataframe de atributos de vértices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk5Bx6XSc6rB"
      },
      "source": [
        "edges = pd.DataFrame([[e.source, e.target] for e in g_karate.es],\n",
        "                     columns = [\"source\", \"target\"])\n",
        "display(edges)\n",
        "\n",
        "node_features = pd.DataFrame({\"class\": [0 if type_ == 1 else 1 for type_ in g_karate.vs[\"Faction\"]]})\n",
        "display(node_features.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos el grafo con atributos."
      ],
      "metadata": {
        "id": "yRS8OamA7s6u"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPaSILTz6Vkk"
      },
      "source": [
        "G_S = sg.StellarGraph(node_features, edges) #agrego comunidad\n",
        "\n",
        "print(G_S.info()) #ahora tiene el atributo 'class'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiPykCJE9kI-"
      },
      "source": [
        "Ahora tenemos que elegir que nodos vamos a usar para entrenar y cuales para testing. Esto podríamos hacerlo con la máscara definida anteriormente, pero optamos por sortearlos nuevamente con fines ilustrativos. \n",
        "\n",
        "Atención: Esto **no significa que vayamos a usar un subgrafo para entrenar**. Simplemente que a la hora de calcular la función objetivo vamos a tener en cuenta solo alguno de los vértices (pero usaremos todo el grafo para construir la red de mensajes).\n",
        "\n",
        "En particular, vamos a elegir solo 2 vértices de cada clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYC7PG1GigqM"
      },
      "outputs": [],
      "source": [
        "train = node_features.groupby(\"class\").sample(2, random_state=42).copy()\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_yn8sFYnx00"
      },
      "source": [
        "El resto de los vértices serán para testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dm2PkqWD-hdq"
      },
      "outputs": [],
      "source": [
        "test = node_features[~node_features.index.isin(train.index)].copy()\n",
        "display(test.head())\n",
        "\n",
        "print(test.shape) # 26 + 8 = 34"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdpxmK71_NNt"
      },
      "source": [
        "Para usar StellarGraph necesitamos transformar la categoría clase en una lista de atributos binarios donde cada columna indica si el nodo es de dicha clase o no. Esto se conoce como `One Hot Encoding`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zi2WkBOi_Ezc"
      },
      "outputs": [],
      "source": [
        "train_dummy = pd.get_dummies(train[\"class\"])\n",
        "display(train_dummy.head())\n",
        "\n",
        "test_dummy = pd.get_dummies(test[\"class\"])\n",
        "display(test_dummy.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGY-MbsH_4e5"
      },
      "source": [
        "Los próximos pasos son necesarios para que StellarGraph pueda trabajar con los datos que les pasamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeaYaVeN_yMa"
      },
      "outputs": [],
      "source": [
        "generator = FullBatchNodeGenerator(G_S, method=\"gcn\") # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tx8zgZ_nADTC"
      },
      "outputs": [],
      "source": [
        "train_gen = generator.flow(\n",
        "    train_dummy.index, # Estos son los indices usados para el set de train\n",
        "    train_dummy.values, # Estos es una matrix de numpy con los valores correspondientes a las clases\n",
        "    use_ilocs=False # Esto se usa para indicar que los indices son \"nombres\" y no posisciones\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkJZ1Tp0CLNA"
      },
      "outputs": [],
      "source": [
        "gcn = GCN(layer_sizes=[4, 4, 2], activations=[\"tanh\", \"tanh\", \"tanh\"], generator=generator, dropout=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5zCU3MkCLI_"
      },
      "outputs": [],
      "source": [
        "x_inp, x_out = gcn.in_out_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kzipsOACLGk"
      },
      "outputs": [],
      "source": [
        "predictions = layers.Dense(units=train_dummy.shape[1], activation=\"softmax\")(x_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8btflLQCLD9"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=x_inp, outputs=predictions)\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=0.01),\n",
        "    loss=losses.categorical_crossentropy,\n",
        "    metrics=[\"acc\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Si0GBM9fCLB8"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=200,\n",
        "    verbose=2,\n",
        "    shuffle=False,  # this should be False, since shuffling data means shuffling the whole graph\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEggoHP8CK-U"
      },
      "outputs": [],
      "source": [
        "sg.utils.plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKe8S60Erw7F"
      },
      "source": [
        "Finalmente, podemos revisar el resultado de la clasificación en el set de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIDgPhImCK5n"
      },
      "outputs": [],
      "source": [
        "test_gen = generator.flow(test_dummy.index, test_dummy.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62q64QFsrggd"
      },
      "outputs": [],
      "source": [
        "out = model.predict(test_gen)\n",
        "\n",
        "print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P36W5X77pFvz"
      },
      "outputs": [],
      "source": [
        "print(\"Las comunidades reales: \\n\", test['class'].to_numpy()) \n",
        "\n",
        "print(\"Las comunidades predichas: \\n\", out[0].argmax(axis=1)) # Calcular la clasificación de cada nodo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuH5jUYjDtBU"
      },
      "outputs": [],
      "source": [
        "test_metrics = model.evaluate(test_gen)\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for name, val in zip(model.metrics_names, test_metrics):\n",
        "    print(\"\\t{}: {:0.4f}\".format(name, val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-mAjJpesVwU"
      },
      "source": [
        "Y en todo el conjunto de datos, para compararnos con las soluciones anteriores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1cF4OJ_sh06"
      },
      "outputs": [],
      "source": [
        "all_dummy = pd.get_dummies(node_features[\"class\"])\n",
        "display(all_dummy.head())\n",
        "\n",
        "all_gen = generator.flow(all_dummy.index, all_dummy.values)\n",
        "\n",
        "out = model.predict(all_gen)\n",
        "print(out.shape)\n",
        "\n",
        "print(\"Las comunidades reales: \\n\", node_features['class'].to_numpy()) \n",
        "print(\"Las comunidades predichas: \\n\", out[0].argmax(axis=1)) # Calcular la clasificación de cada nodo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj4oiR4rLrmq"
      },
      "source": [
        "#2) CORA: grafo grande de publicaciones científicas\n",
        "\n",
        "CORA tiene $2708$ vértices que representan publicaciones. \n",
        "\n",
        "Cada publicación pertenece a una de $7$ clases posibles.\n",
        "\n",
        "Se conocen las citas entre publicaciones, en un grafo con $5429$ aristas.\n",
        "\n",
        "La biblioteca `stellarGraph` incluye este grafo dentro de sus ejemplos. Lo cargamos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39zmUz2ILtzy"
      },
      "outputs": [],
      "source": [
        "def jaccard_weights(graph, _subjects, edges):\n",
        "    sources = graph.node_features(edges.source)\n",
        "    targets = graph.node_features(edges.target)\n",
        "\n",
        "    intersection = np.logical_and(sources, targets)\n",
        "    union = np.logical_or(sources, targets)\n",
        "\n",
        "    return intersection.sum(axis=1) / union.sum(axis=1)\n",
        "\n",
        "dataset = datasets.Cora()\n",
        "display(HTML(dataset.description))\n",
        "G_S, subjects = dataset.load(\n",
        "    largest_connected_component_only=True,\n",
        "    edge_weights=jaccard_weights,\n",
        "    str_node_ids=True,  # Word2Vec requires strings, not ints\n",
        ")\n",
        "\n",
        "N = np.arange(G_S.number_of_nodes())\n",
        "print(G_S.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5oKhb4nOsHq"
      },
      "source": [
        "## 4.1) Laplacian Eigenmap\n",
        "\n",
        "Calculemos el laplaciano, para eso una opción es convertir el grafo a `networkx`y usar la función `laplacian_matrix()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji_LodIkOxT8"
      },
      "outputs": [],
      "source": [
        "G = G_S.to_networkx()\n",
        "print(nx.info(G))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQZ8bZwGOynw"
      },
      "outputs": [],
      "source": [
        "### START CODE HERE\n",
        "### END CODE HERE\n",
        "\n",
        "#podemos imprimir la matriz, o verla como una imagen\n",
        "display(L)\n",
        "\n",
        "plt.imshow(L)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LZ3Pw6qOynx"
      },
      "outputs": [],
      "source": [
        "# Tip: ver ejemplo anterior\n",
        "### START CODE HERE\n",
        "### END CODE HERE\n",
        "\n",
        "print(\"Los valores propios son:\\n\", eig_val)\n",
        "print(\"Los vectores propios estan en una matriz NxN:\\n\", eig_vec.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NyWSsrKjAgI"
      },
      "source": [
        "Calcular el espacio embebido Laplacian Eigenmap de dimensión $128$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzvuIGa9Oyny"
      },
      "outputs": [],
      "source": [
        "d = 128\n",
        "\n",
        "# Tip: ver ejemplo anterior\n",
        "### START CODE HERE\n",
        "### END CODE HERE\n",
        "\n",
        "node_targets_laplacian_eigenmap = subjects.astype(\"category\")\n",
        "\n",
        "print(\"El embebido superficial tiene dimensiones \", encoder_laplacian_eigenmap.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShWGXEANjMqX"
      },
      "source": [
        "Vamos a visualizar en 2D las categorias y los vectores embebidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNwl4wXyRdJS"
      },
      "outputs": [],
      "source": [
        "# Apply t-SNE transformation on node embeddings\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "encoder_laplacian_eigenmap_2d = tsne.fit_transform(encoder_laplacian_eigenmap)\n",
        "\n",
        "# draw the points\n",
        "alpha = 0.7\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(\n",
        "    encoder_laplacian_eigenmap_2d[:, 0],\n",
        "    encoder_laplacian_eigenmap_2d[:, 1],\n",
        "    c=node_targets_laplacian_eigenmap.cat.codes,\n",
        "    cmap=\"jet\",\n",
        "    alpha=0.7,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21K0tLU_RkCL"
      },
      "source": [
        "## 4.2) Node2vec\n",
        "\n",
        "Generamos caminantes con los siguientes parámetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-wYVLQKkpeg"
      },
      "outputs": [],
      "source": [
        "rw = BiasedRandomWalk(G_S)\n",
        "\n",
        "walks = rw.run(\n",
        "    nodes=G_S.nodes(),  # root nodes\n",
        "    length=100,  # maximum length of a random walk\n",
        "    n=10,  # number of random walks per root node\n",
        "    p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
        "    q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
        "    weighted=True,  # for weighted random walks\n",
        "    seed=42,  # random seed fixed for reproducibility\n",
        ")\n",
        "print(\"Number of random walks: {}\".format(len(walks)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdNRpJHJjlFj"
      },
      "source": [
        "Entrenar `node2vec`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C5SWL05kpeh"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "d = 128\n",
        "\n",
        "# Tip: ver ejemplo anterior\n",
        "### START CODE HERE\n",
        "### END CODE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA7DLXYGNThK"
      },
      "outputs": [],
      "source": [
        "# Retrieve node embeddings and corresponding subjects\n",
        "node_ids = model.wv.index2word  # list of node IDs\n",
        "encoder_node2vec = (\n",
        "    model.wv.vectors\n",
        ")  # numpy.ndarray of size number of nodes times embeddings dimensionality\n",
        "# the gensim ordering may not match the StellarGraph one, so rearrange\n",
        "node_targets_node2vec = subjects.loc[node_ids].astype(\"category\")\n",
        "\n",
        "display(encoder_node2vec.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QruHudjMj5rs"
      },
      "source": [
        "Vamos a visualizar en 2D las categorias y los vectores embebidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNye9YGqqWzf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Tip: ver ejemplo anterior\n",
        "### START CODE HERE\n",
        "### END CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGIScjkwRz77"
      },
      "source": [
        "## 4.3) Clasificación de vértices\n",
        "\n",
        "Vamos a predecir la categoría de las publicaciones usando una regresión logística."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTNl5JZLR_eK"
      },
      "outputs": [],
      "source": [
        "df_laplacian = pd.DataFrame(encoder_laplacian_eigenmap)\n",
        "df_laplacian['target']= pd.Categorical(node_targets_laplacian_eigenmap)\n",
        "\n",
        "df_node2vec = pd.DataFrame(encoder_node2vec)\n",
        "df_node2vec['target']= pd.Categorical(node_targets_node2vec)\n",
        "\n",
        "NAMES = [\"Laplacian Eigenmap\", \"Node2Vec\"]\n",
        "dfs = [df_laplacian, df_node2vec]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5ofFM7LR_eM"
      },
      "source": [
        " Elegimos el conjunto de train con 1863 vértices al azar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kfEX6J6R_eM"
      },
      "outputs": [],
      "source": [
        "r = np.random.RandomState(5434)\n",
        "\n",
        "# Tip: ver ejemplo anterior\n",
        "### START CODE HERE\n",
        "### END CODE HERE\n",
        "\n",
        "display(train_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHgcwEhBR_eM"
      },
      "source": [
        "Lo que vamos a hacer aquí es para cada dataset, separar el conjunto de train y test para luego entrenar una regresión.\n",
        "\n",
        "Como sabemos, la regresión no puede aceptar grafos como entrada, pero no tiene problema en aceptar pares de nodos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bMRM6gwR_eM"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "models = []\n",
        "for i, df in enumerate(dfs):\n",
        "  train_df = df[df.index.isin(train_index)]\n",
        "  test_df = df[~df.index.isin(train_index)]\n",
        "  y_train = train_df.pop(\"target\")\n",
        "  y_test = test_df.pop(\"target\")\n",
        "\n",
        "  log_reg = LogisticRegressionCV(Cs=10,\n",
        "                                cv=10,\n",
        "                                tol=0.001,\n",
        "                                max_iter=1000,\n",
        "                                scoring=\"accuracy\",\n",
        "                                verbose=False,\n",
        "                                multi_class=\"ovr\",\n",
        "                                random_state=r)\n",
        "  log_reg.fit(train_df, y_train)\n",
        "  predicted = log_reg.predict(test_df)\n",
        "\n",
        "  acc = accuracy_score(y_test, predicted)\n",
        "  models.append(log_reg)\n",
        "\n",
        "  print(f\"Model {NAMES[i]: <20} has an accuracy of {acc:0.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oowNdquYkQ7m"
      },
      "source": [
        "El resultado debe ser:\n",
        "\n",
        "* Model Laplacian Eigenmap   has an accuracy of 0.7733\n",
        "* Model Node2Vec             has an accuracy of 0.7958 0.8103"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TDPRdqBCBRdZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "public_homework_04+05_embeddings+gnn.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}